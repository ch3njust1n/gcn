{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e497f496",
   "metadata": {},
   "source": [
    "### TODO\n",
    "1. Softmax backprop\n",
    "2. Fix backprop\n",
    "3. Gradient checking\n",
    "4. Visualize loss\n",
    "5. Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8473ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import config\n",
    "import argparse\n",
    "import random\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from pyvis.network import Network\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms.community.modularity_max import greedy_modularity_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a40ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6938d9fe",
   "metadata": {},
   "source": [
    "### Graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4865222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74bd7c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 78)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes(), G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d5c581",
   "metadata": {},
   "source": [
    "### Generate labels from communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c24258",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = greedy_modularity_communities(G)\n",
    "colors = np.zeros(G.number_of_nodes())\n",
    "classes = set()\n",
    "\n",
    "for i, c in enumerate(communities):\n",
    "    colors[list(c)] = i\n",
    "    classes.add(i)\n",
    "    \n",
    "num_classes = len(classes)\n",
    "labels = (np.eye(len(classes))[colors.astype(int)]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e1534",
   "metadata": {},
   "source": [
    "### Color nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2babfe8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local cdn resources have problems on chrome/safari when used in jupyter-notebook. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"colored_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x127f47b20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_color():\n",
    "    return '#%02X%02X%02X' % (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "# uncomment for random colors\n",
    "# color_map = {cls: random_color() for cls in classes}\n",
    "color_map = {0: '#46FB47', 1: '#B9E6B5', 2: '#9F9EBF'}\n",
    "\n",
    "colored_graph = Network(width='100%', notebook=True)\n",
    "\n",
    "for node in G.nodes():\n",
    "    colored_graph.add_node(node, color=color_map[int(colors[node])])\n",
    "    \n",
    "for edge in G.edges():\n",
    "    colored_graph.add_edge(int(edge[0]), int(edge[1]))\n",
    "    \n",
    "colored_graph.show('colored_graph.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a810100",
   "metadata": {},
   "source": [
    "#### Renormalization trick\n",
    "\n",
    "$A$ is the adjacency matrix, $I$ is the identity matrix, and $N$ is the cardinality of the set of nodes in the graph.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\tilde{A} &= A + I_{N}\\\\\n",
    "       \\tilde{\\mathcal{D}}_{ii} &= \\sum_{i}\\tilde{A}_{ij}\\\\\n",
    "    \\hat{\\mathcal{A}}&=\\tilde{\\mathcal{D}}^{-\\frac{1}{2}}\\tilde{\\mathcal{A}}\\tilde{\\mathcal{D}}^{-\\frac{1}{2}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1364cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renormalization(G):\n",
    "    X = nx.to_numpy_matrix(G)\n",
    "    I = np.eye(len(X))\n",
    "    X_tilde = X + I\n",
    "    D_tilde = np.zeros(X.shape, int)\n",
    "    np.fill_diagonal(D_tilde, np.sum(X_tilde, axis=1).flatten())\n",
    "    D_tilde = np.linalg.inv(D_tilde)\n",
    "    D_tilde = np.power(D_tilde, 0.5)\n",
    "    return D_tilde @ X_tilde @ D_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77a25749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 4., 5., ..., 2., 0., 0.],\n",
       "        [4., 0., 6., ..., 0., 0., 0.],\n",
       "        [5., 6., 0., ..., 0., 2., 0.],\n",
       "        ...,\n",
       "        [2., 0., 0., ..., 0., 4., 4.],\n",
       "        [0., 0., 2., ..., 4., 0., 5.],\n",
       "        [0., 0., 0., ..., 4., 5., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.to_numpy_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7151e496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02325581 0.11136921 0.13076645 ... 0.06502561 0.         0.        ]\n",
      " [0.11136921 0.03333333 0.18786729 ... 0.         0.         0.        ]\n",
      " [0.13076645 0.18786729 0.02941176 ... 0.         0.0549235  0.        ]\n",
      " ...\n",
      " [0.06502561 0.         0.         ... 0.04545455 0.13655775 0.12182898]\n",
      " [0.         0.         0.0549235  ... 0.13655775 0.02564103 0.11437725]\n",
      " [0.         0.         0.         ... 0.12182898 0.11437725 0.02040816]]\n"
     ]
    }
   ],
   "source": [
    "A_hat = renormalization(G)\n",
    "print(A_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3245bd",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1d53e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glorot_init(in_dim, out_dim):\n",
    "    sd = np.sqrt(6.0 / (in_dim + out_dim))\n",
    "    return np.random.uniform(-sd, sd, size=(in_dim, out_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d36df3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent(object):\n",
    "    def __init__(self, parameters, learning_rate):\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        \n",
    "    def zero_gradients(self):\n",
    "        for layer in self.parameters:\n",
    "            layer.W_grad = np.zeros(layer.W.shape)\n",
    "            layer.b_grad = np.zeros(layer.b.shape)\n",
    "    \n",
    "    \n",
    "    def step(self):\n",
    "        for i, layer in enumerate(self.parameters):\n",
    "            if np.any(np.isnan(layer.b_grad)):\n",
    "                print(f'nans layer {i}')\n",
    "                \n",
    "            layer.W -= self.learning_rate * layer.W_grad\n",
    "            layer.b -= self.learning_rate * layer.b_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1105b6a",
   "metadata": {},
   "source": [
    "### Graph Convolutional Layer\n",
    "\n",
    "$$\n",
    "\\text{ReLU}(\\hat{A}XW^{1}+b^{1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c38d5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCLayer(object):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.W = glorot_init(output_dim, input_dim)\n",
    "        self.W_grad = np.zeros(self.W.shape)\n",
    "        self.b = np.ones((output_dim, 1))\n",
    "        self.b_grad = np.zeros(self.b.shape)\n",
    "        \n",
    "        \n",
    "    def relu(self, x):\n",
    "        return np.vectorize(lambda i : i if i > 0 else 0)(x)\n",
    "    \n",
    "    \n",
    "    def relu_derivative(self, x):\n",
    "        return np.asarray((x > 0) * 1)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    inputs:\n",
    "    G (nx.Graph)   Normalized Laplacian matrix for a static graph.\n",
    "                   Dimensions: N x N where N is the number of nodes.\n",
    "    x (np.ndarray) Embedding matrix\n",
    "                   Dimensions: N x F where F is the number of features.\n",
    "    '''\n",
    "    def __call__(self, G, x):\n",
    "        # (nodes x nodes), (nodes x features), so need to transpose\n",
    "        # before taking linear combination\n",
    "        self.i = x # (nxf)\n",
    "        self.X = (G @ x).T # (n,n) x (n,f) -> (n,f).T -> (f,n)\n",
    "        self.z = self.W @ self.X + self.b # (h,f) x (f,n) + (h,1) -> (h,n). Broadcast bias vector.\n",
    "        self.a = self.relu(self.z) # (h,n), where n is number of samples/nodes\n",
    "        \n",
    "        # print('GC Layer')\n",
    "        # print(f'x.shape: {x.shape}')\n",
    "        # print(f'X.shape: {self.X.shape}')\n",
    "        # print(f'W.shape: {self.W.shape}')\n",
    "        # print(f'b.shape: {self.b.shape}')\n",
    "        # print(f'z.shape: {self.z.shape}')\n",
    "        # print(f'a.shape: {self.a.shape}')\n",
    "        \n",
    "        # transpose so can multiply by adjacency matrix in next layer\n",
    "        return self.a.T # (n,h)\n",
    "    \n",
    "    \n",
    "    def backward(self, error, compute_error=True):\n",
    "        batch_size = self.X.shape[1] # batch size\n",
    "        self.W_grad += (error @ self.X.T)/batch_size # (h,n) x (n,f) -> (h,f) which matches W.shape\n",
    "        \n",
    "        assert not np.any(np.isnan(self.W_grad))\n",
    "       \n",
    "        expected_grad = np.average(error, axis=1, weights=[batch_size]*error[0]) # expected gradient\n",
    "        expected_grad = expected_grad[:, np.newaxis] # add back column dim of 1 to match b_grad shape\n",
    "        \n",
    "        self.b_grad += expected_grad # (h,n)\n",
    "        \n",
    "        assert not np.any(np.isnan(self.b_grad))\n",
    "        \n",
    "        # print(f'self.W.T: {self.W.T.shape}')\n",
    "        # print(f'error: {error.shape}')\n",
    "        # print(f'self.z: {self.z.shape}')\n",
    "        # print(f'self.W.T @ error: {type(self.W.T @ error)}')\n",
    "        # print(f'self.relu_derivative(self.z): {type(self.relu_derivative(self.z))}')\n",
    "        \n",
    "        return self.W.T @ error * self.relu_derivative(self.z) if compute_error else None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5913b5c",
   "metadata": {},
   "source": [
    "### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c227db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(object):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.W = glorot_init(output_dim, input_dim)\n",
    "        self.W_grad = np.zeros(self.W.shape)\n",
    "        self.b = np.ones((self.output_dim, 1))\n",
    "        self.b_grad = np.zeros(self.b.shape)\n",
    "        \n",
    "        \n",
    "    def relu(self, x):\n",
    "        return np.vectorize(lambda i : i if i > 0 else 0)(x)\n",
    "    \n",
    "    \n",
    "    def relu_derivative(self, x):\n",
    "        return (x > 0) * 1\n",
    "    \n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    x (np.ndarray) Inputs to this layer\n",
    "    \n",
    "    outputs:\n",
    "    a (np.ndarray) Output activations\n",
    "    '''\n",
    "    def __call__(self, x):    \n",
    "        self.x = x # (f,n)\n",
    "        self.z = self.W @ x + self.b # (h,f) x (f,n) + (h,1). Broadcast bias vector.\n",
    "        self.a = self.relu(self.z)   # (h,n)\n",
    "        \n",
    "        # print('Linear layer')\n",
    "        # print(f'x.shape: {x.shape}')\n",
    "        # print(f'W.shape: {self.W.shape}')\n",
    "        # print(f'b.shape: {self.b.shape}')\n",
    "        # print(f'z.shape: {self.z.shape}')\n",
    "        \n",
    "        return self.a # (h,n)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    inputs:\n",
    "    error (np.ndarray) Error signal of shape (W.out_dim, batch_size) from subsequent layer\n",
    "    \n",
    "    outputs:\n",
    "    \n",
    "    '''\n",
    "    def backward(self, error):\n",
    "        batch_size = error.shape[1]\n",
    "        # print(f'layer 3 - error: {error.shape}\\tx.T: {self.x.T.shape}')\n",
    "        self.W_grad += (error @ self.x.T) / batch_size # (h,n) x (n,f)\n",
    "        \n",
    "        assert not np.any(np.isnan(self.W_grad))\n",
    "        \n",
    "        self.b_grad += (np.sum(error, axis=1)) / batch_size # (h,n)\n",
    "        \n",
    "        assert not np.any(np.isnan(self.b_grad))\n",
    "        \n",
    "        return self.W.T @ np.multiply(np.array(error), np.array(self.relu_derivative(self.z))) # (f,h) x (h,n) * (h,n)\n",
    "        # (16,34) and (3,34)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85f194d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(object):\n",
    "    def __init__(self, stable=False):\n",
    "        self.stable = stable\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    inputs:\n",
    "    x (np.array) Logits (unnormalized outoputs) from final layer\n",
    "    \n",
    "    outputs:\n",
    "    x (np.array) Class probabilities\n",
    "    '''\n",
    "    def __call__(self, x):\n",
    "        if self.stable:\n",
    "            exps = np.exp(x - np.max(x))\n",
    "            return exps / np.sum(exps)\n",
    "        else:\n",
    "            return np.exp(x)/np.sum(np.exp(x))        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c89d9",
   "metadata": {},
   "source": [
    "### Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db447724",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(object):\n",
    "    def __init__(self, graph, num_classes):\n",
    "        self.G = graph\n",
    "        self.nodes = self.G.shape[0]\n",
    "        self.embedding = np.eye(self.nodes)\n",
    "        self.l0 = GCLayer(self.nodes, 16)\n",
    "        self.l1 = GCLayer(16, 16)\n",
    "        self.l2 = Linear(16, num_classes)\n",
    "        self.softmax = Softmax(stable=False)\n",
    "        self.parameters = [self.l0, self.l1, self.l2]\n",
    "        \n",
    "    \n",
    "    def __call__(self, x):\n",
    "        a0 = self.l0(self.G, x)\n",
    "        \n",
    "        if np.any(np.isnan(a0)):\n",
    "            raise ValueException(f'GCLayer 1 contains nan')\n",
    "        \n",
    "        a1 = self.l1(self.G, a0).T\n",
    "        \n",
    "        if np.any(np.isnan(a1)):\n",
    "            raise ValueException(f'GCLayer 2 contains nan')\n",
    "        \n",
    "        a2 = self.l2(a1)\n",
    "        \n",
    "        if np.any(np.isnan(a2)):\n",
    "            raise ValueException(f'linear layer contains nan')\n",
    "        \n",
    "        return self.softmax(a2)\n",
    "    \n",
    "    \n",
    "    def backward(self, x):\n",
    "        # Transpose errors from (34,3) -> (3,34) because linear weights are (16,34), but transposed for BP\n",
    "        # so computation must be (labels, batch_size) x (batch_size, hidden_dim) to get error @ x.T\n",
    "        d2 = self.l2.backward(x)\n",
    "        # print(f'd2.shape: {d2.shape}')\n",
    "        d1 = self.l1.backward(d2)\n",
    "        # print(f'd1.shape: {d1.shape}')\n",
    "        self.l0.backward(d1, compute_error=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53471abd",
   "metadata": {},
   "source": [
    "### Forward pass\n",
    "\n",
    "#### Layer 1\n",
    "$$\n",
    "\\begin{align}\n",
    "    &\\text{ReLU}\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{W}^{(1)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            w_{1,1} & \\ldots & w_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            w_{16,1} & \\ldots & w_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "        \\Biggl(\n",
    "        \\\n",
    "            \\underset{\\hat{\\mathcal{A}}\\ \\in\\ \\mathbb{R}^{34\\times34}}{\n",
    "            \\begin{bmatrix}\n",
    "                \\alpha_{1,1} & \\ldots & \\alpha_{1,34}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                \\alpha_{34,1} & \\ldots & \\alpha_{34,34}\n",
    "            \\end{bmatrix}}\n",
    "            \\ \n",
    "            \\underset{\\mathcal{X}\\ \\in\\ \\mathbb{R}^{34\\times34}}{\n",
    "            \\begin{bmatrix}\n",
    "                x_{1,1} & \\ldots & x_{1,34}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                x_{34,1} & \\ldots & x_{34,34}\n",
    "            \\end{bmatrix}}\n",
    "        \\\n",
    "        \\Biggl)^{\\top}\n",
    "        +\n",
    "        \\underset{\\mathcal{b}^{(1)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            b_{1,1} & \\ldots & b_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            b_{16,1} & \\ldots & b_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggr)\\\\\n",
    "    =\\\n",
    "    &\\text{ReLU}\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{Z}^{(1)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            z_{1,1} & \\ldots & z_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            z_{16,1} & \\ldots & z_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggr)\\\\\n",
    "    =\n",
    "    &\\quad\\quad\\quad\\underset{\\mathcal{A}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        a_{1,1} & \\ldots & a_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        a_{16,1} & \\ldots & a_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "    \\rightarrow\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{A}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            a_{1,1} & \\ldots & a_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            a_{16,1} & \\ldots & a_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggl)^{\\top}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Layer 2\n",
    "$$\n",
    "\\begin{align}\n",
    "    &\\text{ReLU}\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{W}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times16}}{\n",
    "        \\begin{bmatrix}\n",
    "            w_{1,1} & \\ldots & w_{1,16}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            w_{16,1} & \\ldots & w_{16,16}\n",
    "        \\end{bmatrix}}\n",
    "        \\\n",
    "        \\Biggl(\n",
    "        \\\n",
    "            \\underset{\\hat{\\mathcal{A}}\\ \\in\\ \\mathbb{R}^{34\\times34}}{\n",
    "            \\begin{bmatrix}\n",
    "                \\alpha_{1,1} & \\ldots & \\alpha_{1,34}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                \\alpha_{34,1} & \\ldots & \\alpha_{34,34}\n",
    "            \\end{bmatrix}}\n",
    "            \\\n",
    "            \\underset{\\mathcal{A}^{(2)^{{\\top}}}\\ \\in\\ \\mathbb{R}^{34\\times16}}{\n",
    "            \\begin{bmatrix}\n",
    "                a_{1,1} & \\ldots & a_{1,16}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                a_{34,1} & \\ldots & a_{34,16}\n",
    "            \\end{bmatrix}}\n",
    "        \\\n",
    "        \\Biggl)^{\\top}\n",
    "        +\n",
    "        \\underset{\\mathcal{b}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            b_{1,1} & \\ldots & b_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            b_{16,1} & \\ldots & b_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggr)\\\\\n",
    "    =\\\n",
    "    &\\text{ReLU}\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{Z}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            z_{1,1} & \\ldots & z_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            z_{16,1} & \\ldots & z_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggr)\\\\\n",
    "    =\n",
    "    &\\quad\\quad\\quad\\underset{\\mathcal{A}^{(3)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        a_{1,1} & \\ldots & a_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        a_{16,1} & \\ldots & a_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "    \\rightarrow\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{A}^{(3)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            a_{1,1} & \\ldots & a_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            a_{16,1} & \\ldots & a_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\Biggl)^{\\top}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Layer 3\n",
    "$$\n",
    "\\begin{align}\n",
    "    &\\text{Softmax}\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{W}^{(3)}\\ \\in\\ \\mathbb{R}^{3\\times16}}{\n",
    "        \\begin{bmatrix}\n",
    "            w_{1,1} & \\ldots & w_{1,16}\\\\\n",
    "            w_{2,1} & \\ldots & w_{2,16}\\\\\n",
    "            w_{3,1} & \\ldots & w_{3,16}\n",
    "        \\end{bmatrix}}\n",
    "        \\\n",
    "        \\Biggl(\n",
    "        \\\n",
    "            \\underset{\\hat{\\mathcal{A}}\\ \\in\\ \\mathbb{R}^{34\\times34}}{\n",
    "            \\begin{bmatrix}\n",
    "                \\alpha_{1,1} & \\ldots & \\alpha_{1,34}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                \\alpha_{34,1} & \\ldots & \\alpha_{34,34}\n",
    "            \\end{bmatrix}}\n",
    "            \\ \n",
    "            \\underset{\\mathcal{A}^{(3)^{\\top}}\\ \\in\\ \\mathbb{R}^{34\\times16}}{\n",
    "            \\begin{bmatrix}\n",
    "                a_{1,1} & \\ldots & a_{1,16}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                a_{34,1} & \\ldots & a_{34,16}\n",
    "            \\end{bmatrix}}\n",
    "        \\Biggl)^{\\top}\n",
    "        +\n",
    "        \\underset{\\mathcal{b}^{(3)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            b_{1,1} & \\ldots & b_{1,34}\\\\\n",
    "            b_{2,1} & \\ldots & b_{2,34}\\\\\n",
    "            b_{3,1} & \\ldots & b_{3,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggr)\\\\\n",
    "    =\\\n",
    "    &\\text{Softmax}\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{Z}^{(3)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            z_{1,1} & \\ldots & z_{1,34}\\\\\n",
    "            z_{2,1} & \\ldots & z_{2,34}\\\\\n",
    "            z_{3,1} & \\ldots & z_{3,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggr)\\\\\n",
    "    =\n",
    "    &\\quad\\quad\\quad\\quad\\underset{\\mathcal{A}^{(4)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        a_{1,1} & \\ldots & a_{1,34}\\\\\n",
    "        a_{2,1} & \\ldots & a_{2,34}\\\\\n",
    "        a_{3,1} & \\ldots & a_{3,34}\n",
    "    \\end{bmatrix}}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b928f54c",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "\n",
    "Why we use cross entropy loss for classification when doing MLE:\n",
    "https://en.wikipedia.org/wiki/Cross_entropy#Relation_to_maximum_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "886ecdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_ent(predictions, targets):\n",
    "    N = predictions.shape[1] # (3,34), so index 1 for samples\n",
    "    targets_ = np.squeeze(np.asarray(targets))\n",
    "    predictions_ = np.squeeze(np.asarray(predictions))\n",
    "    ce = -np.sum(targets_*np.log(predictions_))/N\n",
    "    return ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da7eda",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "\n",
    "#### Cross entropy loss\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\delta^{(4)}=&\\quad\\frac{\\partial}{\\partial z^{(3)}}\\ \\frac{1}{2} \\Big\\lVert Y-H_{\\mathcal{W},\\mathcal{b}}(\\mathcal{X})\\Big\\rVert^{2}\\\\\n",
    "    =&\\quad\\mathcal{A}^{(4)}-Y\\\\\n",
    "    =&\\underset{\\mathcal{A}^{(4)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        a_{1,1} & \\ldots & a_{1,34}\\\\\n",
    "        a_{2,1} & \\ldots & a_{2,34}\\\\\n",
    "        a_{3,1} & \\ldots & a_{3,34}\n",
    "    \\end{bmatrix}}\n",
    "    -\n",
    "    \\underset{\\mathcal{Y}^{(4)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        y_{1,1} & \\ldots & y_{1,34}\\\\\n",
    "        y_{2,1} & \\ldots & y_{2,34}\\\\\n",
    "        y_{3,1} & \\ldots & y_{3,34}\n",
    "    \\end{bmatrix}}\\\\\n",
    "    =&\\underset{\\mathcal{\\delta}^{(4)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        d_{2,1} & \\ldots & d_{2,34}\\\\\n",
    "        d_{3,1} & \\ldots & d_{3,34}\n",
    "    \\end{bmatrix}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Layer 3\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\nabla W^{(3)} =& \\delta^{(4)}A^{(3)^{\\top}}\\\\\n",
    "    =& \n",
    "    \\underset{\\mathcal{\\delta}^{(4)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        d_{2,1} & \\ldots & d_{2,34}\\\\\n",
    "        d_{3,1} & \\ldots & d_{3,34}\n",
    "    \\end{bmatrix}}\n",
    "    \\\n",
    "    \\underset{\\mathcal{A}^{(3)^{\\top}}\\ \\in\\ \\mathbb{R}^{34\\times16}}{\n",
    "    \\begin{bmatrix}\n",
    "        a_{1,1} & \\ldots & a_{1,16}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        a_{34,1} & \\ldots & a_{34,16}\n",
    "    \\end{bmatrix}}\\\\\n",
    "    =&\n",
    "    \\underset{\\nabla\\mathcal{W}^{(3)}\\ \\in\\ \\mathbb{R}^{3\\times16}}{\n",
    "    \\begin{bmatrix}\n",
    "        w_{1,1} & \\ldots & w_{1,16}\\\\\n",
    "        w_{2,1} & \\ldots & w_{2,16}\\\\\n",
    "        w_{3,1} & \\ldots & w_{3,16}\n",
    "    \\end{bmatrix}}\\\\\n",
    "    \\nabla b^{(3)}=&\\delta^{(4)}\\\\\n",
    "    =&\\underset{\\mathcal{\\delta}^{(4)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        d_{2,1} & \\ldots & d_{2,34}\\\\\n",
    "        d_{3,1} & \\ldots & d_{3,34}\n",
    "    \\end{bmatrix}}\\\\\n",
    "    \\delta^{(3)} =&\\mathcal{W}^{(3)^{\\top}}\\delta^{(4)}\\odot\\frac{\\partial}{\\partial z^{(2)}}\\text{ReLU}(z^{(2)})\\\\\n",
    "    =&\n",
    "    \\underset{\\mathcal{W}^{(3)^{\\top}}\\ \\in\\ \\mathbb{R}^{16\\times3}}{\n",
    "    \\begin{bmatrix}\n",
    "        w_{1,1} & w_{1,2} & w_{1,3}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        w_{16,1} & w_{16,2} & w_{16,3}\n",
    "    \\end{bmatrix}}\n",
    "    \\\n",
    "    \\underset{\\mathcal{\\delta}^{(4)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        d_{2,1} & \\ldots & d_{2,34}\\\\\n",
    "        d_{3,1} & \\ldots & d_{3,34}\n",
    "    \\end{bmatrix}}\n",
    "    \\odot\n",
    "    \\frac{\\partial}{\\partial z^{(2)}}\n",
    "    \\text{ReLU}\n",
    "    \\Biggl(\n",
    "    \\ \n",
    "        \\underset{\\mathcal{Z}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            z_{1,1} & \\ldots & z_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            z_{16,1} & \\ldots & z_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\ \\Biggl)\\\\\n",
    "    =&\n",
    "    \\underset{\\mathcal{\\delta}^{(3)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        d_{16,1} & \\ldots & d_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Layer 2\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\nabla W^{(2)} =& \\delta^{(3)}A^{(2)^{\\top}}\\\\\n",
    "    =&\n",
    "    \\underset{\\mathcal{\\delta}^{(3)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        d_{16,1} & \\ldots & d_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "    \\\n",
    "    \\underset{\\mathcal{A}^{(2)^{{\\top}}}\\ \\in\\ \\mathbb{R}^{34\\times16}}{\n",
    "            \\begin{bmatrix}\n",
    "                a_{1,1} & \\ldots & a_{1,16}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                a_{34,1} & \\ldots & a_{34,16}\n",
    "            \\end{bmatrix}}\\\\\n",
    "    \\nabla b^{(2)} =& \\delta^{(3)}\\\\\n",
    "    =&\n",
    "    \\underset{\\mathcal{\\delta}^{(3)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        d_{16,1} & \\ldots & d_{16,34}\n",
    "    \\end{bmatrix}}\\\\\n",
    "    \\delta^{(2)} =&\\mathcal{W}^{(2)^{\\top}}\\delta^{(3)}\\odot\\frac{\\partial}{\\partial z^{(1)}}\\text{ReLU}(z^{(1)})\\\\\n",
    "    =&\n",
    "    \\underset{\\mathcal{W}^{(2)^{\\top}}\\ \\in\\ \\mathbb{R}^{16\\times16}}{\n",
    "    \\begin{bmatrix}\n",
    "        w_{1,1} & \\ldots & w_{1,16}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        w_{16,1} & \\ldots & w_{16,16}\n",
    "    \\end{bmatrix}}\n",
    "    \\\n",
    "    \\underset{\\mathcal{\\delta}^{(3)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        d_{16,1} & \\ldots & d_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "    \\\n",
    "    \\odot\\frac{\\partial}{\\partial z^{(1)}}\\text{ReLU}\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{Z}^{(1)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            z_{1,1} & \\ldots & z_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            z_{16,1} & \\ldots & z_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggl)\\\\\n",
    "    =&\n",
    "    \\underset{\\mathcal{\\delta}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        d_{16,1} & \\ldots & d_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Layer 1\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\nabla W^{(1)} =& \\delta^{(2)}\\mathcal{X}^{\\top}\\\\\n",
    "    =&\n",
    "    \\underset{\\mathcal{\\delta}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        d_{16,1} & \\ldots & d_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "    \\ \n",
    "    \\underset{\\mathcal{X^{\\top}}\\ \\in\\ \\mathbb{R}^{34\\times34}}{\n",
    "            \\begin{bmatrix}\n",
    "                x_{1,1} & \\ldots & x_{1,34}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                x_{34,1} & \\ldots & x_{34,34}\n",
    "            \\end{bmatrix}}\\\\\n",
    "    \\nabla b^{(1)} =& \\delta^{(2)}\\\\\n",
    "    =& \\underset{\\mathcal{\\delta}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        d_{16,1} & \\ldots & d_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ac871",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e1a4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss, epochs, features, labels, opt):\n",
    "    for e in range(epochs):\n",
    "        output = model(features)\n",
    "        # print(f'output: {output.shape}')\n",
    "        # print(f'labels: {labels.shape}')\n",
    "        \n",
    "        loss_val = loss(output, labels)\n",
    "        deriv_loss = output - labels\n",
    "        \n",
    "        # print(f'loss: {loss}')\n",
    "        # print(f'loss_deriv: {deriv_loss}')\n",
    "        \n",
    "        try:\n",
    "            model.backward(deriv_loss)\n",
    "            opt.step()\n",
    "            opt.zero_gradients()\n",
    "        except:\n",
    "            print(f'error at epoch {e}')\n",
    "            sys.exit(0)\n",
    "        \n",
    "        if e % 100 == 0:\n",
    "            print(f'epoch {e} loss: {loss_val.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e8e41",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7c1dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1500\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f408834d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 4.641784190237314\n",
      "epoch 100 loss: 6.074964310677431\n",
      "epoch 200 loss: 9.772071338166521\n",
      "epoch 300 loss: 15.992957182789423\n",
      "epoch 400 loss: 27.049481278511518\n",
      "epoch 500 loss: 47.94807358455519\n",
      "epoch 600 loss: 91.69153579258953\n",
      "epoch 700 loss: 198.9631999851007\n",
      "error at epoch 788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g8/zrrwsczs5lj4l0n6h5nhm2800000gn/T/ipykernel_50440/119200337.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x)/np.sum(np.exp(x))\n",
      "/var/folders/g8/zrrwsczs5lj4l0n6h5nhm2800000gn/T/ipykernel_50440/119200337.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.exp(x)/np.sum(np.exp(x))\n",
      "/var/folders/g8/zrrwsczs5lj4l0n6h5nhm2800000gn/T/ipykernel_50440/3904732012.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  ce = -np.sum(targets_*np.log(predictions_))/N\n",
      "/var/folders/g8/zrrwsczs5lj4l0n6h5nhm2800000gn/T/ipykernel_50440/3904732012.py:5: RuntimeWarning: invalid value encountered in multiply\n",
      "  ce = -np.sum(targets_*np.log(predictions_))/N\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loss, epochs, features, labels, opt)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mderiv_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     opt\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn [15], line 35\u001b[0m, in \u001b[0;36mGCN.backward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Transpose errors from (34,3) -> (3,34) because linear weights are (16,34), but transposed for BP\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# so computation must be (labels, batch_size) x (batch_size, hidden_dim) to get error @ x.T\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     d2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# print(f'd2.shape: {d2.shape}')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [13], line 52\u001b[0m, in \u001b[0;36mLinear.backward\u001b[0;34m(self, error)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_grad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (error \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m/\u001b[39m batch_size \u001b[38;5;66;03m# (h,n) x (n,f)\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_grad))\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_grad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39msum(error, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m/\u001b[39m batch_size \u001b[38;5;66;03m# (h,n)\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn [19], line 4\u001b[0m\n\u001b[1;32m      3\u001b[0m opt \u001b[38;5;241m=\u001b[39m GradientDescent(model\u001b[38;5;241m.\u001b[39mparameters, lr)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_ent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [17], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loss, epochs, features, labels, opt)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mSystemExit\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10/envs/ml/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2042\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2040\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2041\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2042\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2043\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2044\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2045\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2046\u001b[0m         \u001b[38;5;66;03m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   2047\u001b[0m         \u001b[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   2048\u001b[0m         \u001b[38;5;66;03m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10/envs/ml/lib/python3.10/site-packages/IPython/core/ultratb.py:579\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10/envs/ml/lib/python3.10/site-packages/IPython/core/ultratb.py:446\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    443\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    444\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    445\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 446\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    450\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10/envs/ml/lib/python3.10/site-packages/IPython/core/ultratb.py:1112\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m tb\n\u001b[0;32m-> 1112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10/envs/ml/lib/python3.10/site-packages/IPython/core/ultratb.py:1006\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1003\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10/envs/ml/lib/python3.10/site-packages/IPython/core/ultratb.py:859\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    852\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    856\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m    857\u001b[0m ):\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m    863\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10/envs/ml/lib/python3.10/site-packages/IPython/core/ultratb.py:793\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    791\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(etype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m    792\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 793\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    794\u001b[0m )\n\u001b[1;32m    796\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    797\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10/envs/ml/lib/python3.10/site-packages/IPython/core/ultratb.py:848\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    842\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    843\u001b[0m options \u001b[38;5;241m=\u001b[39m stack_data\u001b[38;5;241m.\u001b[39mOptions(\n\u001b[1;32m    844\u001b[0m     before\u001b[38;5;241m=\u001b[39mbefore,\n\u001b[1;32m    845\u001b[0m     after\u001b[38;5;241m=\u001b[39mafter,\n\u001b[1;32m    846\u001b[0m     pygments_formatter\u001b[38;5;241m=\u001b[39mformatter,\n\u001b[1;32m    847\u001b[0m )\n\u001b[0;32m--> 848\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameInfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[tb_offset:]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10/envs/ml/lib/python3.10/site-packages/stack_data/core.py:564\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[0;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack_data\u001b[39m(\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    554\u001b[0m         collapse_repeated_frames: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    555\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrameInfo\u001b[39m\u001b[38;5;124m'\u001b[39m, RepeatedFrames]]:\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 564\u001b[0m     stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miter_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;66;03m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;66;03m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;66;03m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_frame(frame_or_tb):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10/envs/ml/lib/python3.10/site-packages/stack_data/utils.py:97\u001b[0m, in \u001b[0;36miter_stack\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m frame_or_tb:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m frame_or_tb\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     98\u001b[0m         frame_or_tb \u001b[38;5;241m=\u001b[39m frame_or_tb\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10/envs/ml/lib/python3.10/site-packages/stack_data/utils.py:90\u001b[0m, in \u001b[0;36mis_frame\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[43massert_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTracebackType\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame_or_tb, (types\u001b[38;5;241m.\u001b[39mFrameType,))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10/envs/ml/lib/python3.10/site-packages/stack_data/utils.py:176\u001b[0m, in \u001b[0;36massert_\u001b[0;34m(condition, error)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    175\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAssertionError\u001b[39;00m(error)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = np.eye(G.number_of_nodes())\n",
    "model = GCN(A_hat, num_classes)\n",
    "opt = GradientDescent(model.parameters, lr)\n",
    "train(model, cross_ent, epochs, features, labels, opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
