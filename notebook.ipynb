{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e497f496",
   "metadata": {},
   "source": [
    "### TODO\n",
    "1. [GCN Backprop](https://github.com/dmlc/dgl/issues/4021)\n",
    "2. Visualize loss\n",
    "3. [Embeddings](https://beta.openai.com/docs/guides/embeddings/what-are-embeddings)\n",
    "4. Node embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8473ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import config\n",
    "import argparse\n",
    "import random\n",
    "import visdom\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from pyvis.network import Network\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms.community.modularity_max import greedy_modularity_communities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f085c8e4",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a40ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "epochs = 20000\n",
    "lr = 0.001\n",
    "hidden_dim = 16\n",
    "hidden_dim2 = 20\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b494ca73",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34e4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_in_visdom(data, title='', xlabel='', ylabel=''):\n",
    "    vis = visdom.Visdom()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.plot(data)\n",
    "    vis.matplot(plt)\n",
    "    \n",
    "    vis.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6938d9fe",
   "metadata": {},
   "source": [
    "### Graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4865222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74bd7c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes, num_edges = G.number_of_nodes(), G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d5c581",
   "metadata": {},
   "source": [
    "### Generate labels from communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3c24258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.shape: (3, 34)\t classes: 3\t samples: 34\n",
      "[2 1 1 1 2 2 2 1 0 1 2 2 1 1 0 0 2 1 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "communities = greedy_modularity_communities(G)\n",
    "colors = np.zeros(G.number_of_nodes())\n",
    "classes = set()\n",
    "\n",
    "for i, c in enumerate(communities):\n",
    "    colors[list(c)] = i\n",
    "    classes.add(i)\n",
    "    \n",
    "num_classes = len(classes)\n",
    "labels = (np.eye(len(classes))[colors.astype(int)]).T\n",
    "\n",
    "classes, samples = labels.shape\n",
    "print(f'labels.shape: {labels.shape}\\t classes: {classes}\\t samples: {samples}')\n",
    "\n",
    "# each element after argmax represents the class and index represents the node.\n",
    "print(np.argmax(labels, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e1534",
   "metadata": {},
   "source": [
    "### Color nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2babfe8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local cdn resources have problems on chrome/safari when used in jupyter-notebook. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"colored_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1294ca2d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_color():\n",
    "    return '#%02X%02X%02X' % (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "# uncomment for random colors\n",
    "# color_map = {cls: random_color() for cls in classes}\n",
    "color_map = {0: '#46FB47', 1: '#B9E6B5', 2: '#9F9EBF'}\n",
    "\n",
    "colored_graph = Network(width='100%', notebook=True)\n",
    "\n",
    "for node in G.nodes():\n",
    "    colored_graph.add_node(node, color=color_map[int(colors[node])])\n",
    "    \n",
    "for edge in G.edges():\n",
    "    colored_graph.add_edge(int(edge[0]), int(edge[1]))\n",
    "    \n",
    "colored_graph.show('colored_graph.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a810100",
   "metadata": {},
   "source": [
    "#### Renormalization trick\n",
    "\n",
    "$A$ is the adjacency matrix, $I$ is the identity matrix, and $N$ is the cardinality of the set of nodes in the graph.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\tilde{A} &= A + I_{N}\\\\\n",
    "       \\tilde{\\mathcal{D}}_{ii} &= \\sum_{i}\\tilde{A}_{ij}\\\\\n",
    "    \\hat{\\mathcal{A}}&=\\tilde{\\mathcal{D}}^{-\\frac{1}{2}}\\tilde{\\mathcal{A}}\\tilde{\\mathcal{D}}^{-\\frac{1}{2}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056b5d6b",
   "metadata": {},
   "source": [
    "In this notebook, each column of the design matrix `A_hat` corresponds to a single node and each row is a feature dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1364cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renormalization(G):\n",
    "    A = np.asarray(nx.to_numpy_matrix(G))\n",
    "    I = np.eye(len(A))\n",
    "    A_tilde = A + I\n",
    "    D_tilde = np.zeros(A.shape, int)\n",
    "    np.fill_diagonal(D_tilde, np.sum(A_tilde, axis=1).flatten())\n",
    "    D_tilde = np.linalg.inv(D_tilde)\n",
    "    D_tilde = np.power(D_tilde, 0.5)\n",
    "    return D_tilde @ A_tilde @ D_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a25749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 4., 5., ..., 2., 0., 0.],\n",
       "        [4., 0., 6., ..., 0., 0., 0.],\n",
       "        [5., 6., 0., ..., 0., 2., 0.],\n",
       "        ...,\n",
       "        [2., 0., 0., ..., 0., 4., 4.],\n",
       "        [0., 0., 2., ..., 4., 0., 5.],\n",
       "        [0., 0., 0., ..., 4., 5., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.to_numpy_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7151e496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02325581 0.11136921 0.13076645 ... 0.06502561 0.         0.        ]\n",
      " [0.11136921 0.03333333 0.18786729 ... 0.         0.         0.        ]\n",
      " [0.13076645 0.18786729 0.02941176 ... 0.         0.0549235  0.        ]\n",
      " ...\n",
      " [0.06502561 0.         0.         ... 0.04545455 0.13655775 0.12182898]\n",
      " [0.         0.         0.0549235  ... 0.13655775 0.02564103 0.11437725]\n",
      " [0.         0.         0.         ... 0.12182898 0.11437725 0.02040816]]\n",
      "(34, 34)\n"
     ]
    }
   ],
   "source": [
    "# Must pre-process offline\n",
    "A_hat = renormalization(G)\n",
    "print(A_hat)\n",
    "print(A_hat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3300c",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "526a9ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_nodes (34): [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]\n",
      "test_nodes  (0): []\n"
     ]
    }
   ],
   "source": [
    "train_split = 1\n",
    "test_split = 1 - train_split\n",
    "train_nodes = random.sample(list(range(34)), int(train_split * num_nodes))\n",
    "test_nodes = list(set(range(34)) - set(train_nodes))\n",
    "\n",
    "train_nodes.sort()\n",
    "test_nodes.sort()\n",
    "print(f'train_nodes ({len(train_nodes)}): {train_nodes}')\n",
    "print(f'test_nodes  ({len(test_nodes)}): {test_nodes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b51db41",
   "metadata": {},
   "source": [
    "### Train-Test Masks Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3959c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = np.zeros((num_nodes, num_nodes))\n",
    "train_mask[train_nodes, :] = np.ones(num_nodes)\n",
    "train_mask.T[train_nodes, :] = np.ones(num_nodes)\n",
    "test_mask = np.logical_not(train_mask).astype(int)\n",
    "\n",
    "assert (train_mask + test_mask == np.ones((num_nodes, num_nodes))).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862aa4db",
   "metadata": {},
   "source": [
    "### Train-Test Masks Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45c5234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3245bd",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1d53e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(model, scheme):\n",
    "    for i, layer in enumerate(model.parameters):\n",
    "        model.parameters[i].W = scheme(*layer.W.shape)\n",
    "        model.parameters[i].b = scheme(*layer.b.shape)\n",
    "        \n",
    "    return model\n",
    "\n",
    "def glorot_init(in_dim, out_dim):\n",
    "    sd = np.sqrt(6.0 / (in_dim + out_dim))\n",
    "    return np.random.uniform(-sd, sd, size=(in_dim, out_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d36df3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent(object):\n",
    "    def __init__(self, parameters, learning_rate):\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        \n",
    "    def zero_gradients(self):\n",
    "        for layer in self.parameters:\n",
    "            layer.dW = np.zeros(layer.W.shape)\n",
    "            layer.db = np.zeros(layer.b.shape)\n",
    "    \n",
    "    \n",
    "    def step(self):\n",
    "        for i, layer in enumerate(self.parameters):\n",
    "            # TODO: Replace with assertion\n",
    "            if np.any(np.isnan(layer.db)):\n",
    "                print(f'nans layer {i}')\n",
    "                \n",
    "            layer.W -= self.learning_rate * layer.dW\n",
    "            layer.b -= self.learning_rate * layer.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31551367",
   "metadata": {},
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad2e8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_(x):\n",
    "    return (x > 0).astype(int)\n",
    "\n",
    "def softmax(x, axis=0):\n",
    "    return np.exp(x)/np.sum(np.exp(x), axis=axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1105b6a",
   "metadata": {},
   "source": [
    "### Graph Convolutional Layer\n",
    "\n",
    "$$\n",
    "\\text{ReLU}(\\hat{A}XW^{1}+b^{1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c38d5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCLayer(object):\n",
    "    def __init__(self, input_dim, output_dim, name=''):\n",
    "        self.name = name\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.W = glorot_init(output_dim, input_dim)\n",
    "        self.dW = np.zeros(self.W.shape)\n",
    "        self.b = np.ones((output_dim, 1))\n",
    "        self.db = np.zeros(self.b.shape)\n",
    "        self.H = None\n",
    "            \n",
    "    '''\n",
    "    inputs:\n",
    "    G (nx.Graph)   Normalized Laplacian matrix for a static graph.\n",
    "                   Dimensions: N x N where N is the number of nodes.\n",
    "    x (np.ndarray) Embedding matrix\n",
    "                   Dimensions: N x F where F is the number of features.\n",
    "    '''\n",
    "    def __call__(self, G, x, activation=None):\n",
    "        if not activation:\n",
    "            activation = lambda x: x\n",
    "            \n",
    "        # (nodes x nodes), (nodes x features), so need to transpose\n",
    "        # before taking linear combination\n",
    "        self.z = x # (n,f)\n",
    "        \n",
    "        # need to apply the activations along feature/hidden dimension\n",
    "        # since x is (n,f), transpose to apply activations, then transpose back\n",
    "        # to dot with the adjacency matrix\n",
    "        self.a = activation(x.T).T\n",
    "        \n",
    "        # (n,n) x (n,f) -> (n,f).T -> (f,n) so can left-multiply weight with features\n",
    "        # this is purely stylistic preference.\n",
    "        X = (G @ self.a).T\n",
    "        \n",
    "        #print(f'({self.name}) W.shape: {self.W.shape}\\t X.shape: {X.shape}')\n",
    "        \n",
    "        # transpose so can multiply by adjacency matrix in next layer, (n,h)\n",
    "        self.H = (self.W @ X + self.b).T # (h,f) x (f,n) + (h,1) -> (h,n). Broadcast bias vector.\n",
    "        return self.H\n",
    "    \n",
    "    \n",
    "    def backward(self, G, error, derivative=None):\n",
    "        if not derivative:\n",
    "            derivative = lambda x: x\n",
    "            \n",
    "        # (l1) W.T.shape: (16, 20)\t error.shape: (20, 34)\t a.shape: (34, 16)\t z.shape: (34, 16)\n",
    "        #print(f'({self.name}) W.T.shape: {self.W.T.shape}\\t error.shape: {error.shape}\\t a.shape: {self.a.shape}\\t z.shape: {self.z.shape}')\n",
    "        #sys.exit(0)\n",
    "        #self.dW = error @ self.a.T # (h,n) @ (n,f) -> (h,f) which matches W.shape\n",
    "        self.dW = error @ self.a\n",
    "        self.db = np.sum(error, axis=1, keepdims=True) # (h,n)\n",
    "        \n",
    "        # (h,f) @ (f,n) * ((n,n) @ (n,f)).T\n",
    "        return self.W.T @ error * (G @ derivative(self.z)).T\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5913b5c",
   "metadata": {},
   "source": [
    "### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c227db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(object):\n",
    "    def __init__(self, input_dim, output_dim, name=''):\n",
    "        self.name = name\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.W = glorot_init(output_dim, input_dim)\n",
    "        self.dW = np.zeros(self.W.shape)\n",
    "        self.b = np.ones((self.output_dim, 1))\n",
    "        self.db = np.zeros(self.b.shape)    \n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    x (np.ndarray) Inputs to this layer\n",
    "    \n",
    "    outputs:\n",
    "    a (np.ndarray) Output activations\n",
    "    '''\n",
    "    def __call__(self, x, activation=None):\n",
    "        if not activation:\n",
    "            activation = lambda x: x\n",
    "            \n",
    "        self.z = x # (f,n)\n",
    "        self.a = activation(x)\n",
    "        #print(f'({self.name}) W.shape: {self.W.shape}\\t a.shape: {self.a.shape}')\n",
    "        return self.W @ self.a + self.b # (h,f) x (f,n) + (h,1) -> (h,n). Broadcast bias vector.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    inputs:\n",
    "    error (np.ndarray) Error signal of shape (W.out_dim, batch_size) from subsequent layer\n",
    "    \n",
    "    outputs:\n",
    "    \n",
    "    '''\n",
    "    def backward(self, error, derivative=None):\n",
    "        if not derivative:\n",
    "            derivative = lambda x: x\n",
    "            \n",
    "        batch_size = error.shape[1]\n",
    "        \n",
    "        #print(f'({self.name}) W.T.shape: {self.W.T.shape}\\t error.shape: {error.shape}\\t a.T.shape: {self.a.T.shape}\\t z.shape: {self.z.shape}')\n",
    "        \n",
    "        self.dW = error @ self.a.T # (h,n) x (n,f)        \n",
    "        self.db = np.sum(error, axis=1, keepdims=True) # (h,n)\n",
    "        \n",
    "        return self.W.T @ error * derivative(self.z) # (f,h) x (h,n) * (h,n)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c89d9",
   "metadata": {},
   "source": [
    "### Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db447724",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(object):\n",
    "    def __init__(self, graph, num_classes):\n",
    "        self.G = graph\n",
    "        self.nodes = self.G.shape[0]\n",
    "        self.embedding = np.eye(self.nodes)\n",
    "        self.l0 = GCLayer(self.nodes, hidden_dim, name='l0')\n",
    "        self.l1 = GCLayer(hidden_dim, hidden_dim2, name='l1')\n",
    "        self.l2 = Linear(hidden_dim2, num_classes, name='l2')\n",
    "        self.parameters = [self.l0, self.l1, self.l2]\n",
    "        \n",
    "    \n",
    "    def __call__(self, x):\n",
    "        a0 = self.l0(self.G, x, activation=relu)\n",
    "        a1 = self.l1(self.G, a0, activation=relu).T # transpose b/c Linear layer expects (f,n)\n",
    "        a2 = self.l2(a1)\n",
    "        return softmax(a2)\n",
    "    \n",
    "    \n",
    "    def backward(self, x):\n",
    "        # Transpose errors from (34,3) -> (3,34) because linear weights are (16,34), but transposed for BP\n",
    "        # so computation must be (labels, batch_size) x (batch_size, hidden_dim) to get error @ x.T\n",
    "        d2 = self.l2.backward(x, derivative=relu_)\n",
    "        d1 = self.l1.backward(self.G, d2, derivative=relu_)\n",
    "        self.l0.backward(self.G, d1, derivative=None)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53471abd",
   "metadata": {},
   "source": [
    "### Forward pass\n",
    "\n",
    "#### Layer 1\n",
    "$$\n",
    "\\begin{align}\n",
    "    &\\text{ReLU}\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{W}^{(1)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            w_{1,1} & \\ldots & w_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            w_{16,1} & \\ldots & w_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "        \\Biggl(\n",
    "        \\\n",
    "            \\underset{\\hat{\\mathcal{A}}\\ \\in\\ \\mathbb{R}^{34\\times34}}{\n",
    "            \\begin{bmatrix}\n",
    "                \\alpha_{1,1} & \\ldots & \\alpha_{1,34}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                \\alpha_{34,1} & \\ldots & \\alpha_{34,34}\n",
    "            \\end{bmatrix}}\n",
    "            \\ \n",
    "            \\underset{\\mathcal{X}\\ \\in\\ \\mathbb{R}^{34\\times34}}{\n",
    "            \\begin{bmatrix}\n",
    "                x_{1,1} & \\ldots & x_{1,34}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                x_{34,1} & \\ldots & x_{34,34}\n",
    "            \\end{bmatrix}}\n",
    "        \\\n",
    "        \\Biggl)^{\\top}\n",
    "        +\n",
    "        \\underset{\\mathcal{b}^{(1)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            b_{1,1} & \\ldots & b_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            b_{16,1} & \\ldots & b_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggr)\\\\\n",
    "    =\\\n",
    "    &\\text{ReLU}\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{Z}^{(1)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            z_{1,1} & \\ldots & z_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            z_{16,1} & \\ldots & z_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggr)\\\\\n",
    "    =\n",
    "    &\\quad\\quad\\quad\\underset{\\mathcal{A}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        a_{1,1} & \\ldots & a_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        a_{16,1} & \\ldots & a_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "    \\rightarrow\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{A}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            a_{1,1} & \\ldots & a_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            a_{16,1} & \\ldots & a_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggl)^{\\top}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Layer 2\n",
    "$$\n",
    "\\begin{align}\n",
    "    &\\text{ReLU}\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{W}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times16}}{\n",
    "        \\begin{bmatrix}\n",
    "            w_{1,1} & \\ldots & w_{1,16}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            w_{16,1} & \\ldots & w_{16,16}\n",
    "        \\end{bmatrix}}\n",
    "        \\\n",
    "        \\Biggl(\n",
    "        \\\n",
    "            \\underset{\\hat{\\mathcal{A}}\\ \\in\\ \\mathbb{R}^{34\\times34}}{\n",
    "            \\begin{bmatrix}\n",
    "                \\alpha_{1,1} & \\ldots & \\alpha_{1,34}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                \\alpha_{34,1} & \\ldots & \\alpha_{34,34}\n",
    "            \\end{bmatrix}}\n",
    "            \\\n",
    "            \\underset{\\mathcal{A}^{(2)^{{\\top}}}\\ \\in\\ \\mathbb{R}^{34\\times16}}{\n",
    "            \\begin{bmatrix}\n",
    "                a_{1,1} & \\ldots & a_{1,16}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                a_{34,1} & \\ldots & a_{34,16}\n",
    "            \\end{bmatrix}}\n",
    "        \\\n",
    "        \\Biggl)^{\\top}\n",
    "        +\n",
    "        \\underset{\\mathcal{b}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            b_{1,1} & \\ldots & b_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            b_{16,1} & \\ldots & b_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggr)\\\\\n",
    "    =\\\n",
    "    &\\text{ReLU}\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{Z}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            z_{1,1} & \\ldots & z_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            z_{16,1} & \\ldots & z_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggr)\\\\\n",
    "    =\n",
    "    &\\quad\\quad\\quad\\underset{\\mathcal{A}^{(3)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        a_{1,1} & \\ldots & a_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        a_{16,1} & \\ldots & a_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "    \\rightarrow\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{A}^{(3)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            a_{1,1} & \\ldots & a_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            a_{16,1} & \\ldots & a_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\Biggl)^{\\top}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Layer 3\n",
    "$$\n",
    "\\begin{align}\n",
    "    &\\text{Softmax}\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{W}^{(3)}\\ \\in\\ \\mathbb{R}^{3\\times16}}{\n",
    "        \\begin{bmatrix}\n",
    "            w_{1,1} & \\ldots & w_{1,16}\\\\\n",
    "            w_{2,1} & \\ldots & w_{2,16}\\\\\n",
    "            w_{3,1} & \\ldots & w_{3,16}\n",
    "        \\end{bmatrix}}\n",
    "        \\\n",
    "        \\Biggl(\n",
    "        \\\n",
    "            \\underset{\\hat{\\mathcal{A}}\\ \\in\\ \\mathbb{R}^{34\\times34}}{\n",
    "            \\begin{bmatrix}\n",
    "                \\alpha_{1,1} & \\ldots & \\alpha_{1,34}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                \\alpha_{34,1} & \\ldots & \\alpha_{34,34}\n",
    "            \\end{bmatrix}}\n",
    "            \\ \n",
    "            \\underset{\\mathcal{A}^{(3)^{\\top}}\\ \\in\\ \\mathbb{R}^{34\\times16}}{\n",
    "            \\begin{bmatrix}\n",
    "                a_{1,1} & \\ldots & a_{1,16}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                a_{34,1} & \\ldots & a_{34,16}\n",
    "            \\end{bmatrix}}\n",
    "        \\Biggl)^{\\top}\n",
    "        +\n",
    "        \\underset{\\mathcal{b}^{(3)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            b_{1,1} & \\ldots & b_{1,34}\\\\\n",
    "            b_{2,1} & \\ldots & b_{2,34}\\\\\n",
    "            b_{3,1} & \\ldots & b_{3,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggr)\\\\\n",
    "    =\\\n",
    "    &\\text{Softmax}\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{Z}^{(3)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            z_{1,1} & \\ldots & z_{1,34}\\\\\n",
    "            z_{2,1} & \\ldots & z_{2,34}\\\\\n",
    "            z_{3,1} & \\ldots & z_{3,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggr)\\\\\n",
    "    =\n",
    "    &\\quad\\quad\\quad\\quad\\underset{\\mathcal{A}^{(4)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        a_{1,1} & \\ldots & a_{1,34}\\\\\n",
    "        a_{2,1} & \\ldots & a_{2,34}\\\\\n",
    "        a_{3,1} & \\ldots & a_{3,34}\n",
    "    \\end{bmatrix}}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b928f54c",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "\n",
    "Why we use cross entropy loss for classification when doing MLE:\n",
    "https://en.wikipedia.org/wiki/Cross_entropy#Relation_to_maximum_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886ecdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_ent(predictions, targets):\n",
    "    N = predictions.shape[1] # (3,34), so index 1 for samples\n",
    "    targets_ = np.squeeze(np.asarray(targets))\n",
    "    predictions_ = np.squeeze(np.asarray(predictions))\n",
    "    ce = -np.sum(targets_*np.log(predictions_))/N\n",
    "    return ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da7eda",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "\n",
    "#### Cross entropy loss\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\delta^{(4)}=&\\quad\\frac{\\partial}{\\partial z^{(3)}}\\ \\frac{1}{2} \\Big\\lVert Y-H_{\\mathcal{W},\\mathcal{b}}(\\mathcal{X})\\Big\\rVert^{2}\\\\\n",
    "    =&\\quad\\mathcal{A}^{(4)}-Y\\\\\n",
    "    =&\\underset{\\mathcal{A}^{(4)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        a_{1,1} & \\ldots & a_{1,34}\\\\\n",
    "        a_{2,1} & \\ldots & a_{2,34}\\\\\n",
    "        a_{3,1} & \\ldots & a_{3,34}\n",
    "    \\end{bmatrix}}\n",
    "    -\n",
    "    \\underset{\\mathcal{Y}^{(4)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        y_{1,1} & \\ldots & y_{1,34}\\\\\n",
    "        y_{2,1} & \\ldots & y_{2,34}\\\\\n",
    "        y_{3,1} & \\ldots & y_{3,34}\n",
    "    \\end{bmatrix}}\\\\\n",
    "    =&\\underset{\\mathcal{\\delta}^{(4)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        d_{2,1} & \\ldots & d_{2,34}\\\\\n",
    "        d_{3,1} & \\ldots & d_{3,34}\n",
    "    \\end{bmatrix}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Layer 3\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\nabla W^{(3)} =& \\delta^{(4)}A^{(3)^{\\top}}\\\\\n",
    "    =& \n",
    "    \\underset{\\mathcal{\\delta}^{(4)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        d_{2,1} & \\ldots & d_{2,34}\\\\\n",
    "        d_{3,1} & \\ldots & d_{3,34}\n",
    "    \\end{bmatrix}}\n",
    "    \\\n",
    "    \\underset{\\mathcal{A}^{(3)^{\\top}}\\ \\in\\ \\mathbb{R}^{34\\times16}}{\n",
    "    \\begin{bmatrix}\n",
    "        a_{1,1} & \\ldots & a_{1,16}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        a_{34,1} & \\ldots & a_{34,16}\n",
    "    \\end{bmatrix}}\\\\\n",
    "    =&\n",
    "    \\underset{\\nabla\\mathcal{W}^{(3)}\\ \\in\\ \\mathbb{R}^{3\\times16}}{\n",
    "    \\begin{bmatrix}\n",
    "        w_{1,1} & \\ldots & w_{1,16}\\\\\n",
    "        w_{2,1} & \\ldots & w_{2,16}\\\\\n",
    "        w_{3,1} & \\ldots & w_{3,16}\n",
    "    \\end{bmatrix}}\\\\\n",
    "    \\nabla b^{(3)}=&\\delta^{(4)}\\\\\n",
    "    =&\\underset{\\mathcal{\\delta}^{(4)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        d_{2,1} & \\ldots & d_{2,34}\\\\\n",
    "        d_{3,1} & \\ldots & d_{3,34}\n",
    "    \\end{bmatrix}}\\\\\n",
    "    \\delta^{(3)} =&\\mathcal{W}^{(3)^{\\top}}\\delta^{(4)}\\odot\\frac{\\partial}{\\partial z^{(2)}}\\text{ReLU}(z^{(2)})\\\\\n",
    "    =&\n",
    "    \\underset{\\mathcal{W}^{(3)^{\\top}}\\ \\in\\ \\mathbb{R}^{16\\times3}}{\n",
    "    \\begin{bmatrix}\n",
    "        w_{1,1} & w_{1,2} & w_{1,3}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        w_{16,1} & w_{16,2} & w_{16,3}\n",
    "    \\end{bmatrix}}\n",
    "    \\\n",
    "    \\underset{\\mathcal{\\delta}^{(4)}\\ \\in\\ \\mathbb{R}^{3\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        d_{2,1} & \\ldots & d_{2,34}\\\\\n",
    "        d_{3,1} & \\ldots & d_{3,34}\n",
    "    \\end{bmatrix}}\n",
    "    \\odot\n",
    "    \\frac{\\partial}{\\partial z^{(2)}}\n",
    "    \\text{ReLU}\n",
    "    \\Biggl(\n",
    "    \\ \n",
    "        \\underset{\\mathcal{Z}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            z_{1,1} & \\ldots & z_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            z_{16,1} & \\ldots & z_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\ \\Biggl)\\\\\n",
    "    =&\n",
    "    \\underset{\\mathcal{\\delta}^{(3)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        d_{16,1} & \\ldots & d_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Layer 2\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\nabla W^{(2)} =& \\delta^{(3)}A^{(2)^{\\top}}\\\\\n",
    "    =&\n",
    "    \\underset{\\mathcal{\\delta}^{(3)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        d_{16,1} & \\ldots & d_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "    \\\n",
    "    \\underset{\\mathcal{A}^{(2)^{{\\top}}}\\ \\in\\ \\mathbb{R}^{34\\times16}}{\n",
    "            \\begin{bmatrix}\n",
    "                a_{1,1} & \\ldots & a_{1,16}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                a_{34,1} & \\ldots & a_{34,16}\n",
    "            \\end{bmatrix}}\\\\\n",
    "    \\nabla b^{(2)} =& \\delta^{(3)}\\\\\n",
    "    =&\n",
    "    \\underset{\\mathcal{\\delta}^{(3)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        d_{16,1} & \\ldots & d_{16,34}\n",
    "    \\end{bmatrix}}\\\\\n",
    "    \\delta^{(2)} =&\\mathcal{W}^{(2)^{\\top}}\\delta^{(3)}\\odot\\frac{\\partial}{\\partial z^{(1)}}\\text{ReLU}(z^{(1)})\\\\\n",
    "    =&\n",
    "    \\underset{\\mathcal{W}^{(2)^{\\top}}\\ \\in\\ \\mathbb{R}^{16\\times16}}{\n",
    "    \\begin{bmatrix}\n",
    "        w_{1,1} & \\ldots & w_{1,16}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        w_{16,1} & \\ldots & w_{16,16}\n",
    "    \\end{bmatrix}}\n",
    "    \\\n",
    "    \\underset{\\mathcal{\\delta}^{(3)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        d_{16,1} & \\ldots & d_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "    \\\n",
    "    \\odot\\frac{\\partial}{\\partial z^{(1)}}\\text{ReLU}\n",
    "    \\Biggl(\n",
    "    \\\n",
    "        \\underset{\\mathcal{Z}^{(1)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "        \\begin{bmatrix}\n",
    "            z_{1,1} & \\ldots & z_{1,34}\\\\\n",
    "            \\vdots & \\ddots & \\vdots\\\\\n",
    "            z_{16,1} & \\ldots & z_{16,34}\n",
    "        \\end{bmatrix}}\n",
    "    \\\n",
    "    \\Biggl)\\\\\n",
    "    =&\n",
    "    \\underset{\\mathcal{\\delta}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        d_{16,1} & \\ldots & d_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Layer 1\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\nabla W^{(1)} =& \\delta^{(2)}\\mathcal{X}^{\\top}\\\\\n",
    "    =&\n",
    "    \\underset{\\mathcal{\\delta}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        d_{16,1} & \\ldots & d_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "    \\ \n",
    "    \\underset{\\mathcal{X^{\\top}}\\ \\in\\ \\mathbb{R}^{34\\times34}}{\n",
    "            \\begin{bmatrix}\n",
    "                x_{1,1} & \\ldots & x_{1,34}\\\\\n",
    "                \\vdots & \\ddots & \\vdots\\\\\n",
    "                x_{34,1} & \\ldots & x_{34,34}\n",
    "            \\end{bmatrix}}\\\\\n",
    "    \\nabla b^{(1)} =& \\delta^{(2)}\\\\\n",
    "    =& \\underset{\\mathcal{\\delta}^{(2)}\\ \\in\\ \\mathbb{R}^{16\\times34}}{\n",
    "    \\begin{bmatrix}\n",
    "        d_{1,1} & \\ldots & d_{1,34}\\\\\n",
    "        \\vdots & \\ddots & \\vdots\\\\\n",
    "        d_{16,1} & \\ldots & d_{16,34}\n",
    "    \\end{bmatrix}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ac871",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "749835d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss, epochs, features, labels, test_graph, opt):\n",
    "    losses, accuracy = [], []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # output: (3, 34)\n",
    "        output = model(features)\n",
    "        loss_val = loss(output, labels)\n",
    "        deriv_loss = output - labels\n",
    "        \n",
    "        model.backward(deriv_loss)\n",
    "        opt.step()\n",
    "        opt.zero_gradients()\n",
    "        \n",
    "        if e % 100 == 0:\n",
    "            # use train_graph for debugging\n",
    "            acc = np.sum(np.argmax(model(train_graph), axis=0) == np.argmax(labels, axis=0)) / num_nodes\n",
    "            # print(f'(epoch {e}) loss: {loss_val} acc: {acc}')\n",
    "            \n",
    "            losses.append(loss_val)\n",
    "            accuracy.append(acc)\n",
    "\n",
    "    return losses, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f408834d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch 0) loss: 2.1078050084343127 acc: 0.4117647058823529\n",
      "(epoch 100) loss: 0.9515257401321427 acc: 0.5\n",
      "(epoch 200) loss: 0.7692635717867594 acc: 0.6176470588235294\n",
      "(epoch 300) loss: 0.535067726800178 acc: 0.8529411764705882\n",
      "(epoch 400) loss: 0.3637318878755125 acc: 0.9117647058823529\n",
      "(epoch 500) loss: 0.2618203985022061 acc: 0.9117647058823529\n",
      "(epoch 600) loss: 0.19898480517648293 acc: 0.9117647058823529\n",
      "(epoch 700) loss: 0.15767252659699568 acc: 0.9117647058823529\n",
      "(epoch 800) loss: 0.12822769292558325 acc: 0.9411764705882353\n",
      "(epoch 900) loss: 0.10588696545036932 acc: 0.9411764705882353\n",
      "(epoch 1000) loss: 0.08804958411577225 acc: 0.9411764705882353\n",
      "(epoch 1100) loss: 0.073437306188014 acc: 0.9411764705882353\n",
      "(epoch 1200) loss: 0.06133603108388278 acc: 0.9411764705882353\n",
      "(epoch 1300) loss: 0.051239582148142705 acc: 0.9411764705882353\n",
      "(epoch 1400) loss: 0.042827817270201955 acc: 0.9411764705882353\n",
      "(epoch 1500) loss: 0.0358687183641308 acc: 0.9411764705882353\n",
      "(epoch 1600) loss: 0.03015952886420833 acc: 0.9411764705882353\n",
      "(epoch 1700) loss: 0.025509328571136452 acc: 0.9411764705882353\n",
      "(epoch 1800) loss: 0.02173583221391857 acc: 0.9411764705882353\n",
      "(epoch 1900) loss: 0.0186744278582257 acc: 0.9411764705882353\n",
      "(epoch 2000) loss: 0.016183452895077655 acc: 0.9411764705882353\n",
      "(epoch 2100) loss: 0.014145990756954056 acc: 0.9411764705882353\n",
      "(epoch 2200) loss: 0.012471078243829809 acc: 0.9411764705882353\n",
      "(epoch 2300) loss: 0.011082304434641364 acc: 0.9411764705882353\n",
      "(epoch 2400) loss: 0.009919856001226534 acc: 0.9411764705882353\n",
      "(epoch 2500) loss: 0.008938961369294266 acc: 0.9411764705882353\n",
      "(epoch 2600) loss: 0.008104716116702859 acc: 0.9411764705882353\n",
      "(epoch 2700) loss: 0.007389850221587704 acc: 0.9411764705882353\n",
      "(epoch 2800) loss: 0.006772918592566557 acc: 0.9411764705882353\n",
      "(epoch 2900) loss: 0.006236653521509345 acc: 0.9411764705882353\n",
      "(epoch 3000) loss: 0.005767707707206624 acc: 0.9411764705882353\n",
      "(epoch 3100) loss: 0.0053551129138518765 acc: 0.9411764705882353\n",
      "(epoch 3200) loss: 0.004990036050312003 acc: 0.9411764705882353\n",
      "(epoch 3300) loss: 0.004665329575729473 acc: 0.9411764705882353\n",
      "(epoch 3400) loss: 0.004375143584105047 acc: 0.9411764705882353\n",
      "(epoch 3500) loss: 0.004114654638855443 acc: 0.9705882352941176\n",
      "(epoch 3600) loss: 0.003879795079854349 acc: 0.9705882352941176\n",
      "(epoch 3700) loss: 0.0036671511518761987 acc: 0.9705882352941176\n",
      "(epoch 3800) loss: 0.0034739034687429984 acc: 0.9705882352941176\n",
      "(epoch 3900) loss: 0.0032977035133372893 acc: 0.9705882352941176\n",
      "(epoch 4000) loss: 0.0031364979190724516 acc: 0.9705882352941176\n",
      "(epoch 4100) loss: 0.002988542129975357 acc: 0.9705882352941176\n",
      "(epoch 4200) loss: 0.0028523496517641983 acc: 0.9705882352941176\n",
      "(epoch 4300) loss: 0.0027266644632668404 acc: 0.9705882352941176\n",
      "(epoch 4400) loss: 0.002610396568759728 acc: 0.9705882352941176\n",
      "(epoch 4500) loss: 0.002502581284943237 acc: 0.9705882352941176\n",
      "(epoch 4600) loss: 0.0024023773119377406 acc: 0.9705882352941176\n",
      "(epoch 4700) loss: 0.0023090574611771587 acc: 0.9705882352941176\n",
      "(epoch 4800) loss: 0.0022219537260599583 acc: 0.9705882352941176\n",
      "(epoch 4900) loss: 0.0021405013313954414 acc: 0.9705882352941176\n",
      "(epoch 5000) loss: 0.0020641949015453307 acc: 0.9705882352941176\n",
      "(epoch 5100) loss: 0.0019925798815998586 acc: 0.9705882352941176\n",
      "(epoch 5200) loss: 0.0019252668917142978 acc: 0.9705882352941176\n",
      "(epoch 5300) loss: 0.0018618893122887064 acc: 0.9705882352941176\n",
      "(epoch 5400) loss: 0.0018021362888637326 acc: 0.9705882352941176\n",
      "(epoch 5500) loss: 0.001745712133318407 acc: 0.9705882352941176\n",
      "(epoch 5600) loss: 0.0016923624590834759 acc: 0.9705882352941176\n",
      "(epoch 5700) loss: 0.0016418580935816708 acc: 0.9705882352941176\n",
      "(epoch 5800) loss: 0.0015939805494945953 acc: 0.9705882352941176\n",
      "(epoch 5900) loss: 0.001548545456125697 acc: 0.9705882352941176\n",
      "(epoch 6000) loss: 0.0015053731847575562 acc: 0.9705882352941176\n",
      "(epoch 6100) loss: 0.0014643094647681172 acc: 0.9705882352941176\n",
      "(epoch 6200) loss: 0.0014252117304043598 acc: 0.9705882352941176\n",
      "(epoch 6300) loss: 0.001387943993672815 acc: 0.9705882352941176\n",
      "(epoch 6400) loss: 0.0013523880689533775 acc: 0.9705882352941176\n",
      "(epoch 6500) loss: 0.0013184357948844293 acc: 0.9705882352941176\n",
      "(epoch 6600) loss: 0.001285983031995496 acc: 0.9705882352941176\n",
      "(epoch 6700) loss: 0.0012549411159049817 acc: 0.9705882352941176\n",
      "(epoch 6800) loss: 0.0012252180408578283 acc: 0.9705882352941176\n",
      "(epoch 6900) loss: 0.0011967369056304134 acc: 0.9705882352941176\n",
      "(epoch 7000) loss: 0.0011694222038138434 acc: 0.9705882352941176\n",
      "(epoch 7100) loss: 0.001143210881480192 acc: 0.9705882352941176\n",
      "(epoch 7200) loss: 0.0011180384606162426 acc: 0.9705882352941176\n",
      "(epoch 7300) loss: 0.0010938483739413834 acc: 0.9705882352941176\n",
      "(epoch 7400) loss: 0.0010705839686372285 acc: 0.9705882352941176\n",
      "(epoch 7500) loss: 0.001048197026509013 acc: 0.9705882352941176\n",
      "(epoch 7600) loss: 0.0010266417756152248 acc: 0.9705882352941176\n",
      "(epoch 7700) loss: 0.0010058700512912103 acc: 0.9705882352941176\n",
      "(epoch 7800) loss: 0.000985845487340797 acc: 0.9705882352941176\n",
      "(epoch 7900) loss: 0.000966529089459882 acc: 0.9705882352941176\n",
      "(epoch 8000) loss: 0.0009478882278203109 acc: 0.9705882352941176\n",
      "(epoch 8100) loss: 0.0009298830779497602 acc: 0.9705882352941176\n",
      "(epoch 8200) loss: 0.000912487603518325 acc: 0.9705882352941176\n",
      "(epoch 8300) loss: 0.000895675422680487 acc: 0.9705882352941176\n",
      "(epoch 8400) loss: 0.0008794133545382296 acc: 0.9705882352941176\n",
      "(epoch 8500) loss: 0.0008636783834475285 acc: 0.9705882352941176\n",
      "(epoch 8600) loss: 0.0008484437540148075 acc: 0.9705882352941176\n",
      "(epoch 8700) loss: 0.0008336889889431455 acc: 0.9705882352941176\n",
      "(epoch 8800) loss: 0.0008193933517450626 acc: 0.9705882352941176\n",
      "(epoch 8900) loss: 0.0008055345227448972 acc: 0.9705882352941176\n",
      "(epoch 9000) loss: 0.0007920954069581781 acc: 0.9705882352941176\n",
      "(epoch 9100) loss: 0.0007790568877214729 acc: 0.9705882352941176\n",
      "(epoch 9200) loss: 0.0007664025978741616 acc: 0.9705882352941176\n",
      "(epoch 9300) loss: 0.0007541150783545924 acc: 0.9705882352941176\n",
      "(epoch 9400) loss: 0.000742180031837017 acc: 0.9705882352941176\n",
      "(epoch 9500) loss: 0.0007305830638727902 acc: 0.9705882352941176\n",
      "(epoch 9600) loss: 0.000719311204323843 acc: 0.9705882352941176\n",
      "(epoch 9700) loss: 0.0007083502028223831 acc: 0.9705882352941176\n",
      "(epoch 9800) loss: 0.0006976885597657542 acc: 0.9705882352941176\n",
      "(epoch 9900) loss: 0.0006873145289957881 acc: 0.9705882352941176\n",
      "(epoch 10000) loss: 0.0006772171857384291 acc: 0.9705882352941176\n",
      "(epoch 10100) loss: 0.0006673864947036779 acc: 0.9705882352941176\n",
      "(epoch 10200) loss: 0.0006578113363839811 acc: 0.9705882352941176\n",
      "(epoch 10300) loss: 0.0006484827600587551 acc: 0.9705882352941176\n",
      "(epoch 10400) loss: 0.0006393926572263945 acc: 0.9705882352941176\n",
      "(epoch 10500) loss: 0.0006305298735018961 acc: 0.9705882352941176\n",
      "(epoch 10600) loss: 0.0006218890151434387 acc: 0.9705882352941176\n",
      "(epoch 10700) loss: 0.0006134605628810595 acc: 0.9705882352941176\n",
      "(epoch 10800) loss: 0.000605237518182654 acc: 0.9705882352941176\n",
      "(epoch 10900) loss: 0.0005972127531825144 acc: 0.9705882352941176\n",
      "(epoch 11000) loss: 0.0005893792300844672 acc: 0.9705882352941176\n",
      "(epoch 11100) loss: 0.0005817306610135731 acc: 0.9705882352941176\n",
      "(epoch 11200) loss: 0.0005742623068342407 acc: 0.9705882352941176\n",
      "(epoch 11300) loss: 0.0005669642061014569 acc: 0.9705882352941176\n",
      "(epoch 11400) loss: 0.0005598341147014059 acc: 0.9705882352941176\n",
      "(epoch 11500) loss: 0.0005528654469347078 acc: 0.9705882352941176\n",
      "(epoch 11600) loss: 0.0005460530450047971 acc: 0.9705882352941176\n",
      "(epoch 11700) loss: 0.0005393921328266273 acc: 0.9705882352941176\n",
      "(epoch 11800) loss: 0.0005328767936701403 acc: 0.9705882352941176\n",
      "(epoch 11900) loss: 0.0005265043867580088 acc: 0.9705882352941176\n",
      "(epoch 12000) loss: 0.0005202691177551047 acc: 0.9705882352941176\n",
      "(epoch 12100) loss: 0.0005141670933364103 acc: 0.9705882352941176\n",
      "(epoch 12200) loss: 0.0005081942773825847 acc: 0.9705882352941176\n",
      "(epoch 12300) loss: 0.0005023466771539103 acc: 0.9705882352941176\n",
      "(epoch 12400) loss: 0.0004966206215084168 acc: 0.9705882352941176\n",
      "(epoch 12500) loss: 0.0004910125701531831 acc: 0.9705882352941176\n",
      "(epoch 12600) loss: 0.0004855190214617256 acc: 0.9705882352941176\n",
      "(epoch 12700) loss: 0.00048013706541061426 acc: 0.9705882352941176\n",
      "(epoch 12800) loss: 0.00047486136044258624 acc: 0.9705882352941176\n",
      "(epoch 12900) loss: 0.0004696913985832061 acc: 0.9705882352941176\n",
      "(epoch 13000) loss: 0.00046462352247186205 acc: 0.9705882352941176\n",
      "(epoch 13100) loss: 0.0004596546790642552 acc: 0.9705882352941176\n",
      "(epoch 13200) loss: 0.00045478136624866927 acc: 0.9705882352941176\n",
      "(epoch 13300) loss: 0.00045000185834293563 acc: 0.9705882352941176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch 13400) loss: 0.00044531311406550256 acc: 0.9705882352941176\n",
      "(epoch 13500) loss: 0.0004407128492096372 acc: 0.9705882352941176\n",
      "(epoch 13600) loss: 0.0004361990189687217 acc: 0.9705882352941176\n",
      "(epoch 13700) loss: 0.00043176850078564566 acc: 0.9705882352941176\n",
      "(epoch 13800) loss: 0.0004274192057448035 acc: 0.9705882352941176\n",
      "(epoch 13900) loss: 0.0004231493174416804 acc: 0.9705882352941176\n",
      "(epoch 14000) loss: 0.0004189567379389295 acc: 0.9705882352941176\n",
      "(epoch 14100) loss: 0.0004148394438416421 acc: 0.9705882352941176\n",
      "(epoch 14200) loss: 0.00041079545138804585 acc: 0.9705882352941176\n",
      "(epoch 14300) loss: 0.0004068228864885668 acc: 0.9705882352941176\n",
      "(epoch 14400) loss: 0.00040291998523630753 acc: 0.9705882352941176\n",
      "(epoch 14500) loss: 0.00039908491089256354 acc: 0.9705882352941176\n",
      "(epoch 14600) loss: 0.00039531608241970924 acc: 0.9705882352941176\n",
      "(epoch 14700) loss: 0.00039161197367601616 acc: 0.9705882352941176\n",
      "(epoch 14800) loss: 0.00038797086433142193 acc: 0.9705882352941176\n",
      "(epoch 14900) loss: 0.0003843903504461569 acc: 0.9705882352941176\n",
      "(epoch 15000) loss: 0.00038087029372188433 acc: 0.9705882352941176\n",
      "(epoch 15100) loss: 0.0003774087515363587 acc: 0.9705882352941176\n",
      "(epoch 15200) loss: 0.00037400425866613337 acc: 0.9705882352941176\n",
      "(epoch 15300) loss: 0.00037065574154189794 acc: 0.9705882352941176\n",
      "(epoch 15400) loss: 0.0003673612972676902 acc: 0.9705882352941176\n",
      "(epoch 15500) loss: 0.00036412015074395904 acc: 0.9705882352941176\n",
      "(epoch 15600) loss: 0.0003609309156588109 acc: 0.9705882352941176\n",
      "(epoch 15700) loss: 0.0003577927348610453 acc: 0.9705882352941176\n",
      "(epoch 15800) loss: 0.00035470351188777267 acc: 0.9705882352941176\n",
      "(epoch 15900) loss: 0.00035166303398516044 acc: 0.9705882352941176\n",
      "(epoch 16000) loss: 0.00034867024079488564 acc: 0.9705882352941176\n",
      "(epoch 16100) loss: 0.00034572307699208256 acc: 0.9705882352941176\n",
      "(epoch 16200) loss: 0.00034282153271878086 acc: 0.9705882352941176\n",
      "(epoch 16300) loss: 0.00033996424253806304 acc: 0.9705882352941176\n",
      "(epoch 16400) loss: 0.0003371501909311333 acc: 0.9705882352941176\n",
      "(epoch 16500) loss: 0.0003343789787735846 acc: 0.9705882352941176\n",
      "(epoch 16600) loss: 0.00033164828912928186 acc: 0.9705882352941176\n",
      "(epoch 16700) loss: 0.0003289589203082196 acc: 0.9705882352941176\n",
      "(epoch 16800) loss: 0.000326308579255658 acc: 0.9705882352941176\n",
      "(epoch 16900) loss: 0.00032369769710126036 acc: 0.9705882352941176\n",
      "(epoch 17000) loss: 0.00032112417544489244 acc: 0.9705882352941176\n",
      "(epoch 17100) loss: 0.00031858825819070804 acc: 0.9705882352941176\n",
      "(epoch 17200) loss: 0.00031608870523802565 acc: 0.9705882352941176\n",
      "(epoch 17300) loss: 0.000313624872358316 acc: 0.9705882352941176\n",
      "(epoch 17400) loss: 0.0003111962228280608 acc: 0.9705882352941176\n",
      "(epoch 17500) loss: 0.0003088013424611154 acc: 0.9705882352941176\n",
      "(epoch 17600) loss: 0.0003064402709017528 acc: 0.9705882352941176\n",
      "(epoch 17700) loss: 0.0003041123149240927 acc: 0.9705882352941176\n",
      "(epoch 17800) loss: 0.0003018160237336131 acc: 0.9705882352941176\n",
      "(epoch 17900) loss: 0.0002995515935638851 acc: 0.9705882352941176\n",
      "(epoch 18000) loss: 0.000297318129446358 acc: 0.9705882352941176\n",
      "(epoch 18100) loss: 0.0002951150552712038 acc: 0.9705882352941176\n",
      "(epoch 18200) loss: 0.00029294152100246585 acc: 0.9705882352941176\n",
      "(epoch 18300) loss: 0.00029079728787983865 acc: 0.9705882352941176\n",
      "(epoch 18400) loss: 0.0002886816141009347 acc: 0.9705882352941176\n",
      "(epoch 18500) loss: 0.0002865940408759493 acc: 0.9705882352941176\n",
      "(epoch 18600) loss: 0.0002845340822282487 acc: 0.9705882352941176\n",
      "(epoch 18700) loss: 0.00028250088320253057 acc: 0.9705882352941176\n",
      "(epoch 18800) loss: 0.00028049390884896943 acc: 0.9705882352941176\n",
      "(epoch 18900) loss: 0.00027851288560024545 acc: 0.9705882352941176\n",
      "(epoch 19000) loss: 0.0002765574990447064 acc: 0.9705882352941176\n",
      "(epoch 19100) loss: 0.00027462695537287346 acc: 0.9705882352941176\n",
      "(epoch 19200) loss: 0.0002727211014744451 acc: 0.9705882352941176\n",
      "(epoch 19300) loss: 0.00027083941871740904 acc: 0.9705882352941176\n",
      "(epoch 19400) loss: 0.00026898143359765393 acc: 0.9705882352941176\n",
      "(epoch 19500) loss: 0.00026714657432977624 acc: 0.9705882352941176\n",
      "(epoch 19600) loss: 0.0002653346848780005 acc: 0.9705882352941176\n",
      "(epoch 19700) loss: 0.0002635451662729725 acc: 0.9705882352941176\n",
      "(epoch 19800) loss: 0.00026177771865669154 acc: 0.9705882352941176\n",
      "(epoch 19900) loss: 0.0002600321246994373 acc: 0.9705882352941176\n"
     ]
    }
   ],
   "source": [
    "features = np.eye(num_nodes)\n",
    "train_graph = train_mask * A_hat\n",
    "test_graph = test_mask * A_hat\n",
    "model = GCN(train_graph, num_classes)\n",
    "opt = GradientDescent(model.parameters, lr)\n",
    "losses, accuracy = train(model, cross_ent, epochs, features, labels, test_graph, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0168a1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_in_visdom(losses, title=f'(Scratch) {epochs} epochs', xlabel='Epochs', ylabel='Losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e07988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_in_visdom(accuracy, title=f'(Scratch) {epochs} epochs', xlabel='Epochs', ylabel='Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af961eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
