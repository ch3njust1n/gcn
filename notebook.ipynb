{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import argparse\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from pyvis.network import Network\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms.community.modularity_max import greedy_modularity_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 78)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes(), G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500px\"\n",
       "            height=\"500px\"\n",
       "            src=\"karate.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fec4071ddc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphvis = Network(notebook=True)\n",
    "graphvis.from_nx(G)\n",
    "graphvis.show('karate.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 4., 5., ..., 2., 0., 0.],\n",
       "        [4., 0., 6., ..., 0., 0., 0.],\n",
       "        [5., 6., 0., ..., 0., 2., 0.],\n",
       "        ...,\n",
       "        [2., 0., 0., ..., 0., 4., 4.],\n",
       "        [0., 0., 2., ..., 4., 0., 5.],\n",
       "        [0., 0., 0., ..., 4., 5., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.to_numpy_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renormalization(G):\n",
    "    A = nx.to_numpy_matrix(G)\n",
    "    I = np.eye(len(A))\n",
    "    A_tilde = A + I\n",
    "    D_tilde = np.zeros(A.shape, int)\n",
    "    np.fill_diagonal(D_tilde, np.sum(A_tilde, axis=1).flatten())\n",
    "    D_tilde = np.linalg.inv(D_tilde)\n",
    "    D_tilde = np.power(D_tilde, 0.5)\n",
    "    return D_tilde @ A_tilde @ D_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02325581 0.11136921 0.13076645 ... 0.06502561 0.         0.        ]\n",
      " [0.11136921 0.03333333 0.18786729 ... 0.         0.         0.        ]\n",
      " [0.13076645 0.18786729 0.02941176 ... 0.         0.0549235  0.        ]\n",
      " ...\n",
      " [0.06502561 0.         0.         ... 0.04545455 0.13655775 0.12182898]\n",
      " [0.         0.         0.0549235  ... 0.13655775 0.02564103 0.11437725]\n",
      " [0.         0.         0.         ... 0.12182898 0.11437725 0.02040816]]\n"
     ]
    }
   ],
   "source": [
    "A_hat = renormalization(G)\n",
    "print(A_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.eye(G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.piecewise(x, [x <= 0, x > 0], [0, x])\n",
    "    \n",
    "    \n",
    "def relu_derivative(x):\n",
    "    return (x > 0) * 1\n",
    "    \n",
    "    \n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0, keepdims=True)\n",
    "    \n",
    "\n",
    "def cross_ent(pred, labels):\n",
    "    return -np.log(pred)[np.arange(pred.shape[0]), np.argmax(labels, axis=1)]\n",
    "\n",
    "\n",
    "def glorot_init(in_dim, out_dim):\n",
    "    sd = np.sqrt(6.0 / (in_dim + out_dim))\n",
    "    return np.random.uniform(-sd, sd, size=(in_dim, out_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent(object):\n",
    "    def __init__(self, parameters, learning_rate):\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        \n",
    "    def zero_gradients(self):\n",
    "        for layer in self.parameters:\n",
    "            layer.zero_gradients()\n",
    "    \n",
    "    \n",
    "    def step(self):\n",
    "        for layer in self.parameters:\n",
    "            layer.weights -= self.learning_rate * layer.gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCLayer(object):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.weights = glorot_init(np.zeros(input_dim, output_dim))\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        \n",
    "    def __call__(self, G, x):\n",
    "        # Transpose b/c need to store this for backward pass\n",
    "        self._X = (G @ x).T\n",
    "\n",
    "        # Rever the original order of AXW to W(GX).T to save having to compute both\n",
    "        self._H = relu(self.weights @ self._X)\n",
    "\n",
    "        # One last transpose so that the dimensions are correct for the forward pass\n",
    "        return self._H.T\n",
    "    \n",
    "    \n",
    "    def backward(self, G, x):\n",
    "        self.gradients = x\n",
    "        return relu_derivative(np.transpose(self.weights) @ G @ x)\n",
    "    \n",
    "    \n",
    "    def zero_gradients(self):\n",
    "        self.gradients = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(object):\n",
    "    def __init__(self, graph):\n",
    "        self.G = graph\n",
    "        self.num_features = 10\n",
    "        self.embedding = np.array(self.graph.shape[0], self.num_features)\n",
    "        self.l0 = GCLayer(self.num_features, 32)\n",
    "        self.l1 = GCLayer(32, 2)\n",
    "        self.parameters = [self.l0, self.l1]\n",
    "        \n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return softmax(self.l1(self.l0(self.G, x)))\n",
    "    \n",
    "    \n",
    "    def backward(self, x):\n",
    "        self.l0.backward(self.G, self.l1.backward(self.G, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(object):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.W = np.zeros((self.input_dim, self.output_dim))\n",
    "        self.b = np.zeros((self.output_dim, 1))\n",
    "        self.gradient = None\n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.W @ x + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss, epochs, dataset, opt):\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for x, y in dataset:\n",
    "            epoch_loss += loss(model(x), y)\n",
    "            \n",
    "        model.backward()\n",
    "        opt.step()\n",
    "        opt.zero_gradients()\n",
    "        \n",
    "        epoch_loss /= len(dataset)\n",
    "        print(f'epoch {e} loss: {epoch_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(A_hat)\n",
    "opt = GradientDescent(model.parameters, lr)\n",
    "train(model, cross_ent, epochs, features, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one iteration of gradient descent:\n",
    "\n",
    "Compute global gradient as a chain of local gradients using chain rul of calculus\n",
    "\n",
    "For last layer $l$:\n",
    "\n",
    "$$\n",
    "\\delta^{(l)}=\\frac{\\partial}{\\partial z^{(l)}}\\mathcal{L}\n",
    "$$\n",
    "\n",
    "Think of $\\delta^{(l)}$ as serving as the same function as $x$ during the forward pass.\n",
    "\n",
    "For layer i in $l-1$ to $2$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\nabla_{w^{(i)}}\\mathcal{L}&=\\delta^{(i)}a^{(i-1)^{\\top}}\\\\\\\\\n",
    "    \\nabla_{b^{(i)}}\\mathcal{L}&=\\delta^{(i)}\\\\\\\\  \n",
    "    \\delta^{i-1} &= W^{i^{\\top}}\\delta^{i}\\odot\\frac{\\partial}{\\partial z}f(z^{(i-1)})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "For each layer i, apply gradient descent:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    W^{(i)} &= W^{(i)} - \\alpha\\mathbb{E}[\\nabla_{W^{(i)}}]\\\\\n",
    "    b^{(i)} &= b^{(i)} - \\alpha\\mathbb{E}[\\nabla_{b^{(i)}}]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Here the expected gradient is taken over the batch that generated these gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
